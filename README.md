<p align="center">
  <img src="https://img.shields.io/badge/python-3.11+-blue.svg" alt="Python 3.11+">
  <img src="https://img.shields.io/badge/license-MIT-green.svg" alt="License MIT">
  <img src="https://img.shields.io/badge/LLM-Local%20First-purple.svg" alt="Local LLM">
  <img src="https://img.shields.io/badge/MCP-Enabled-orange.svg" alt="MCP Enabled">
</p>

# Antigravirt

**Antigravirt** is a privacy-first, local-running AI Data Analyst that transforms natural language questions into SQL queries, executes them against your databases, and visualizes the results â€” all without your data ever leaving your infrastructure.

<p align="center">
  <img src="img/system/WorkingChat.png" alt="Antigravirt Chat Interface" width="800"/>
</p>

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ—£ï¸ **Natural Language to SQL** | Ask questions like "Show me monthly revenue" and get accurate SQL |
| ğŸ”’ **Privacy First** | Runs 100% locally â€” your data never leaves your infrastructure |
| ğŸ“Š **Interactive Visualizations** | Auto-generates Plotly charts for data insights |
| ğŸ”— **Multi-Source Connectivity** | Connect multiple databases (PostgreSQL, SQLite) via MCP |
| ğŸ¤– **Multi-Agent Architecture** | Powered by LangGraph for robust reasoning and self-correction |
| ğŸ›¡ï¸ **Safe Execution** | Read-only permission model (SELECT only) prevents accidents |
| ğŸ“¡ **Real-time Updates** | WebSocket streaming for live agent progress |
| ğŸ”­ **Full Observability** | Arize Phoenix integration for LLM tracing |

---

## ğŸ–¼ï¸ Screenshots

### Chat Interface with Visualization

The chat interface provides a natural conversation experience with inline visualizations:

<p align="center">
  <img src="img/system/WorkingChat.png" alt="Working Chat with Chart" width="700"/>
</p>

### Multi-Source Data Connectivity

Connect to multiple databases and data sources using the Model Context Protocol (MCP):

<p align="center">
  <img src="img/system/DataSourceMcpServers.png" alt="MCP Data Sources" width="700"/>
</p>

<p align="center">
  <img src="img/system/MultipleDataSourceConnection.png" alt="Connected Data Sources" width="700"/>
</p>

### LLM Observability with Arize Phoenix

Full visibility into your AI pipeline with trace analysis:

<p align="center">
  <img src="img/arize/ListofTraces.png" alt="Arize Phoenix - Trace List" width="700"/>
</p>

<p align="center">
  <img src="img/arize/SingleTrace.png" alt="Arize Phoenix - Single Trace" width="700"/>
</p>

---

## ğŸ› ï¸ Tech Stack

| Layer | Technologies |
|-------|--------------|
| **Backend** | Python 3.11, FastAPI, LangGraph, Pydantic, asyncpg |
| **Frontend** | React 18, TypeScript, Tailwind CSS, Plotly.js |
| **Database** | PostgreSQL 15, SQLite (via MCP) |
| **LLM** | Ollama, LM Studio, or Cloud APIs (OpenAI/Gemini) |
| **Protocol** | Model Context Protocol (MCP) for data connectivity |
| **Observability** | Arize Phoenix for LLM tracing |
| **Infrastructure** | Docker Compose |

---

## ğŸ—ï¸ System Architecture

### Complete System Overview

```mermaid
%%{init: {'theme': 'dark', 'themeVariables': { 'primaryColor': '#6366f1', 'primaryTextColor': '#fff', 'primaryBorderColor': '#4f46e5', 'lineColor': '#94a3b8', 'secondaryColor': '#1e293b', 'tertiaryColor': '#0f172a'}}}%%
flowchart TB
    subgraph CLIENT["ğŸ–¥ï¸ CLIENT LAYER"]
        direction TB
        UI["React Frontend<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Chat Interface<br/>â€¢ Visualization Panel<br/>â€¢ Connection Manager"]
    end

    subgraph GATEWAY["ğŸ”Œ API GATEWAY"]
        direction TB
        REST["REST API<br/>/api/*"]
        WSS["WebSocket Server<br/>/ws/chat"]
    end

    subgraph AGENTS["ğŸ¤– LANGGRAPH AGENT ORCHESTRATION"]
        direction TB
        
        subgraph ROUTING["Intent Router"]
            R{{"ğŸ§­ Router<br/>Intent Classification"}}
        end
        
        subgraph QUERY_PIPELINE["Data Query Pipeline"]
            direction LR
            ARCH["ğŸ“ Architect<br/>Schema Analysis"]
            CODE["âœï¸ Coder<br/>SQL Generation"]
            EXEC["âš¡ Executor<br/>Query Execution"]
        end
        
        subgraph VIZ_PIPELINE["Visualization Pipeline"]
            direction LR
            VIZR{{"ğŸ“Š Viz Router"}}
            VIZ["ğŸ¨ Visualizer<br/>Plotly Generation"]
        end
        
        subgraph ALT_PATHS["Alternative Paths"]
            CHAT["ğŸ’¬ Chat"]
            SCHEMA["ğŸ“‹ Schema"]
            CLARIFY["â“ Clarify"]
        end
        
        FINAL["âœ… Final Responder<br/>Response Synthesis"]
    end

    subgraph MCP_LAYER["ğŸ”— MODEL CONTEXT PROTOCOL (MCP)"]
        direction TB
        MGR["MCP Connection Manager<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Schema Caching (60s TTL)<br/>â€¢ Connection Pooling<br/>â€¢ Dynamic Server Spawning"]
        
        subgraph MCP_SERVERS["MCP Server Fleet"]
            direction LR
            PG["ğŸ˜ PostgreSQL<br/>Server<br/>â”â”â”â”â”â”â”<br/>â€¢ query()<br/>â€¢ get_schema()<br/>â€¢ list_tables()"]
            SQLITE["ğŸ“¦ SQLite<br/>Server<br/>â”â”â”â”â”â”â”<br/>â€¢ query()<br/>â€¢ get_schema()<br/>â€¢ list_tables()"]
            FS["ğŸ“ Filesystem<br/>Server<br/>â”â”â”â”â”â”â”<br/>â€¢ read_file()<br/>â€¢ list_dir()<br/>â€¢ write_file()"]
        end
    end

    subgraph DATA["ğŸ—„ï¸ DATA SOURCES"]
        direction LR
        DB1[("PostgreSQL<br/>Production DB")]
        DB2[("SQLite<br/>Analytics DB")]
        FILES[("Local Files<br/>CSV/JSON")]
    end

    subgraph INTELLIGENCE["ğŸ§  INTELLIGENCE LAYER"]
        direction LR
        LLM["ğŸ¤– Local LLM<br/>â”â”â”â”â”â”â”â”â”â”<br/>Ollama / LM Studio<br/>qwen2.5:7b/14b"]
        PHOENIX["ğŸ“Š Arize Phoenix<br/>â”â”â”â”â”â”â”â”â”â”â”â”<br/>LLM Observability<br/>Trace Analysis"]
    end

    %% Client to Gateway
    UI <-->|"WebSocket<br/>Real-time"| WSS
    UI -->|"HTTP<br/>REST"| REST

    %% Gateway to Agents
    WSS --> R
    REST --> MGR

    %% Router branching
    R -->|"DATA_QUERY"| ARCH
    R -->|"GENERAL_CHAT"| CHAT
    R -->|"SCHEMA_QUESTION"| SCHEMA
    R -->|"AMBIGUOUS"| CLARIFY

    %% Query Pipeline
    ARCH --> CODE --> EXEC
    EXEC --> VIZR
    VIZR -->|"Needs Chart"| VIZ
    VIZR -->|"Text Only"| FINAL
    VIZ --> FINAL

    %% Alt paths to output
    CHAT --> FINAL
    SCHEMA --> FINAL
    CLARIFY --> FINAL

    %% Executor to MCP
    EXEC --> MGR
    MGR --> PG & SQLITE & FS

    %% MCP to Data
    PG --> DB1
    SQLITE --> DB2
    FS --> FILES

    %% LLM connections
    R -.->|"Inference"| LLM
    ARCH -.->|"Inference"| LLM
    CODE -.->|"Inference"| LLM
    VIZ -.->|"Inference"| LLM
    FINAL -.->|"Inference"| LLM

    %% Observability
    R -.->|"Trace"| PHOENIX
    ARCH -.->|"Trace"| PHOENIX
    CODE -.->|"Trace"| PHOENIX
    EXEC -.->|"Trace"| PHOENIX
    VIZ -.->|"Trace"| PHOENIX

    %% Styling
    classDef client fill:#3b82f6,stroke:#2563eb,color:#fff
    classDef gateway fill:#8b5cf6,stroke:#7c3aed,color:#fff
    classDef agent fill:#10b981,stroke:#059669,color:#fff
    classDef mcp fill:#f59e0b,stroke:#d97706,color:#fff
    classDef data fill:#6366f1,stroke:#4f46e5,color:#fff
    classDef intel fill:#ec4899,stroke:#db2777,color:#fff

    class UI client
    class REST,WSS gateway
    class R,ARCH,CODE,EXEC,VIZR,VIZ,CHAT,SCHEMA,CLARIFY,FINAL agent
    class MGR,PG,SQLITE,FS mcp
    class DB1,DB2,FILES data
    class LLM,PHOENIX intel
```

---

### ğŸ”— MCP (Model Context Protocol) Deep Dive

The MCP layer provides a **unified interface** for connecting to heterogeneous data sources:

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart LR
    subgraph AGENT["Agent Layer"]
        EXEC["Executor Node"]
    end

    subgraph MCP_MANAGER["MCP Connection Manager"]
        direction TB
        CACHE["Schema Cache<br/>TTL: 60s"]
        REGISTRY["Connection Registry<br/>connections.json"]
        SPAWNER["Server Spawner<br/>subprocess.Popen"]
    end

    subgraph SERVERS["MCP Server Instances"]
        direction TB
        
        subgraph PG_SERVER["PostgreSQL MCP Server"]
            PG_QUERY["query(sql) â†’ JSON"]
            PG_SCHEMA["get_schema() â†’ DDL"]
            PG_TABLES["list_tables() â†’ [str]"]
        end
        
        subgraph SQLITE_SERVER["SQLite MCP Server"]
            SQ_QUERY["query(sql) â†’ JSON"]
            SQ_SCHEMA["get_schema() â†’ DDL"]
            SQ_TABLES["list_tables() â†’ [str]"]
        end
        
        subgraph FS_SERVER["Filesystem MCP Server"]
            FS_READ["read_file(path) â†’ str"]
            FS_LIST["list_directory() â†’ [str]"]
            FS_WRITE["write_file(path, data)"]
        end
    end

    subgraph TRANSPORT["stdio Transport"]
        STDIN["stdin (JSON-RPC)"]
        STDOUT["stdout (JSON-RPC)"]
    end

    EXEC -->|"get_tool_result()"| MCP_MANAGER
    MCP_MANAGER -->|"spawn if needed"| SERVERS
    SERVERS <-->|"JSON-RPC 2.0"| TRANSPORT

    style CACHE fill:#22c55e,stroke:#16a34a,color:#fff
    style REGISTRY fill:#3b82f6,stroke:#2563eb,color:#fff
    style SPAWNER fill:#f59e0b,stroke:#d97706,color:#fff
```

#### MCP Server Tools Reference

| Server | Tool | Input | Output | Description |
|--------|------|-------|--------|-------------|
| **PostgreSQL** | `query` | `sql: str` | `JSON` | Execute read-only SQL (SELECT only) |
| **PostgreSQL** | `get_schema` | `table_name?: str` | `DDL string` | Get table/column definitions |
| **PostgreSQL** | `list_tables` | â€” | `List[str]` | List all public tables |
| **SQLite** | `query` | `sql: str` | `JSON` | Execute read-only SQL |
| **SQLite** | `get_schema` | `table_name?: str` | `DDL string` | Get schema from sqlite_master |
| **SQLite** | `list_tables` | â€” | `List[str]` | List all tables |
| **Filesystem** | `read_file` | `path: str` | `str` | Read file (max 10MB, sandboxed) |
| **Filesystem** | `list_directory` | `path?: str` | `List[str]` | List directory contents |
| **Filesystem** | `write_file` | `path, data` | `bool` | Write to file (sandboxed) |

---

### ğŸ”­ Arize Phoenix Observability Architecture

Full LLM observability with distributed tracing:

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart TB
    subgraph APP["Application"]
        direction TB
        OTEL["OpenTelemetry<br/>Instrumentor"]
        AGENTS["LangGraph<br/>Agents"]
    end

    subgraph PHOENIX["Arize Phoenix (localhost:6006)"]
        direction TB
        COLLECTOR["OTLP Collector<br/>gRPC/HTTP"]
        
        subgraph STORAGE["Trace Storage"]
            TRACES["Trace Store"]
            SPANS["Span Store"]
        end
        
        subgraph ANALYSIS["Analysis Engine"]
            LATENCY["Latency<br/>Analysis"]
            TOKENS["Token<br/>Counting"]
            EVALS["LLM<br/>Evaluations"]
        end
        
        subgraph UI["Phoenix UI"]
            TREE["Trace Tree<br/>Visualization"]
            METRICS["Performance<br/>Metrics"]
            INSPECT["I/O<br/>Inspector"]
        end
    end

    OTEL -->|"Auto-instrument"| AGENTS
    AGENTS -->|"OTLP Export"| COLLECTOR
    COLLECTOR --> TRACES & SPANS
    TRACES --> LATENCY & TOKENS & EVALS
    LATENCY --> TREE
    TOKENS --> METRICS
    EVALS --> INSPECT

    style OTEL fill:#6366f1,stroke:#4f46e5,color:#fff
    style COLLECTOR fill:#22c55e,stroke:#16a34a,color:#fff
    style UI fill:#f59e0b,stroke:#d97706,color:#000
```

#### Trace Structure Example

```
ğŸ“Š Query: "Show me sales by status as a bar chart"
â”‚
â”œâ”€â”€ ğŸ§­ Router [12ms] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ Input:  "Show me sales by status as a bar chart"
â”‚   â”œâ”€â”€ Output: {"intent": "DATA_QUERY", "confidence": 0.95}
â”‚   â””â”€â”€ Tokens: 156 in / 42 out
â”‚
â”œâ”€â”€ ğŸ“ Architect [8ms] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ Input:  Schema context + Question
â”‚   â”œâ”€â”€ Output: {"tables": ["orders"], "strategy": "aggregate"}
â”‚   â””â”€â”€ Tokens: 892 in / 67 out
â”‚
â”œâ”€â”€ âœï¸ Coder [15ms] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ Input:  Query strategy + Schema
â”‚   â”œâ”€â”€ Output: "SELECT status, COUNT(*) FROM orders GROUP BY status"
â”‚   â””â”€â”€ Tokens: 1024 in / 89 out
â”‚
â”œâ”€â”€ âš¡ Executor [3ms] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ Input:  SQL Query
â”‚   â”œâ”€â”€ Output: [{"status": "completed", "count": 156}, ...]
â”‚   â””â”€â”€ DB Latency: 2.1ms
â”‚
â”œâ”€â”€ ğŸ¨ Visualizer [18ms] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ Input:  Query result + Chart request
â”‚   â”œâ”€â”€ Output: Plotly JSON specification
â”‚   â””â”€â”€ Tokens: 512 in / 234 out
â”‚
â””â”€â”€ âœ… Final Responder [11ms] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â”œâ”€â”€ Input:  Result + Visualization
    â”œâ”€â”€ Output: "Here is the sales breakdown by order status..."
    â””â”€â”€ Tokens: 445 in / 112 out

Total: 67ms | Total Tokens: 3,573
```

#### Key Observability Metrics

| Metric | Description | Typical Value |
|--------|-------------|---------------|
| **Trace Duration** | End-to-end latency | 60-90s (local LLM) |
| **LLM Latency** | Per-inference time | 10-20s per call |
| **Token Usage** | Input + Output tokens | 2,000-5,000 per query |
| **MCP Latency** | Database query time | 1-50ms |
| **Error Rate** | Failed queries | < 5% |

---

### ğŸ” Security Architecture

```mermaid
%%{init: {'theme': 'dark'}}%%
flowchart TB
    subgraph BOUNDARIES["Security Boundaries"]
        direction TB
        
        subgraph SQL_GUARD["SQL Injection Prevention"]
            VALIDATOR["SQL Validator<br/>â”â”â”â”â”â”â”â”â”â”<br/>âœ“ SELECT only<br/>âœ— INSERT/UPDATE/DELETE<br/>âœ— DROP/ALTER/TRUNCATE<br/>âœ— Multiple statements"]
        end
        
        subgraph FS_SANDBOX["Filesystem Sandbox"]
            SANDBOX["Path Validator<br/>â”â”â”â”â”â”â”â”â”â”<br/>âœ“ Within root_dir<br/>âœ— Path traversal (../)<br/>âœ— Absolute paths<br/>âœ— Symlink escape"]
        end
        
        subgraph DATA_PRIVACY["Data Privacy"]
            LOCAL["Local Processing<br/>â”â”â”â”â”â”â”â”â”â”<br/>âœ“ 100% on-premise<br/>âœ“ No external API calls<br/>âœ“ Your data, your control"]
        end
    end
    
    INPUT["User Input"] --> VALIDATOR
    VALIDATOR -->|"Valid"| EXEC["Execute"]
    VALIDATOR -->|"Invalid"| REJECT["Reject"]
    
    FILE_REQ["File Request"] --> SANDBOX
    SANDBOX -->|"Safe Path"| READ["Read File"]
    SANDBOX -->|"Unsafe"| DENY["Deny Access"]
    
    LLM_REQ["LLM Request"] --> LOCAL
    LOCAL --> OLLAMA["Ollama (localhost)"]

    style VALIDATOR fill:#22c55e,stroke:#16a34a,color:#fff
    style SANDBOX fill:#3b82f6,stroke:#2563eb,color:#fff
    style LOCAL fill:#8b5cf6,stroke:#7c3aed,color:#fff
    style REJECT fill:#ef4444,stroke:#dc2626,color:#fff
    style DENY fill:#ef4444,stroke:#dc2626,color:#fff
```

---

### ğŸ“Š Performance Characteristics

| Component | Latency | Throughput | Notes |
|-----------|---------|------------|-------|
| **WebSocket RTT** | < 5ms | 1000 msg/s | Real-time bidirectional |
| **Router Classification** | 10-15s | â€” | Local LLM inference |
| **SQL Generation** | 15-20s | â€” | Complex reasoning |
| **Query Execution** | 1-50ms | â€” | Depends on query complexity |
| **Visualization** | 10-15s | â€” | Plotly spec generation |
| **Schema Cache** | < 1ms | â€” | In-memory, 60s TTL |

> **Note:** Latencies shown are for local LLM (qwen2.5:7b). Cloud LLMs (GPT-4, Claude) reduce inference time to 1-3s per call.

---

## ğŸ“¦ Project Structure

```
antigravirt/
â”œâ”€â”€ backend/                 # FastAPI + LangGraph Agents
â”‚   â”œâ”€â”€ agents/              # LangGraph nodes and prompts
â”‚   â”‚   â”œâ”€â”€ nodes/           # Router, Architect, Coder, Executor, etc.
â”‚   â”‚   â”œâ”€â”€ prompts/         # System prompts for each agent
â”‚   â”‚   â”œâ”€â”€ graph.py         # LangGraph workflow definition
â”‚   â”‚   â””â”€â”€ llm.py           # LLM configuration (Ollama/OpenAI/Gemini)
â”‚   â”œâ”€â”€ api/                 # FastAPI routes and WebSocket handlers
â”‚   â”œâ”€â”€ mcp/                 # Model Context Protocol implementation
â”‚   â”‚   â”œâ”€â”€ manager.py       # Connection manager with caching
â”‚   â”‚   â”œâ”€â”€ servers/         # PostgreSQL, SQLite, Filesystem servers
â”‚   â”‚   â””â”€â”€ tools.py         # MCP tool adapters
â”‚   â”œâ”€â”€ observability/       # Arize Phoenix instrumentation
â”‚   â””â”€â”€ utils/               # Database and helper utilities
â”œâ”€â”€ frontend/                # React Application
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/      # ChatPanel, Sidebar, ConnectionManager
â”‚       â”œâ”€â”€ hooks/           # useWebSocket custom hook
â”‚       â””â”€â”€ types/           # TypeScript interfaces
â”œâ”€â”€ infrastructure/          # Docker & Database Setup
â”‚   â”œâ”€â”€ init.sql             # Database schema
â”‚   â””â”€â”€ docker-compose.yml   # PostgreSQL + Phoenix containers
â”œâ”€â”€ img/                     # Documentation screenshots
â”‚   â”œâ”€â”€ arize/               # Phoenix observability screenshots
â”‚   â””â”€â”€ system/              # UI screenshots
â””â”€â”€ tests/                   # Test suite
```

---

## âš¡ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+
- Docker & Docker Compose
- Ollama (recommended) or LM Studio

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/kaushikkumarkr/Antigravit.git
cd antigravirt

# 2. Backend setup
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt

# 3. Environment configuration
cp .env.example .env
# Edit .env with your LLM and database settings

# 4. Start database (PostgreSQL)
docker-compose -f infrastructure/docker-compose.yml up -d

# 5. Seed sample data
python infrastructure/seed_data.py

# 6. Start Ollama with a model
ollama pull qwen2.5:7b
ollama serve

# 7. Start backend
uvicorn backend.main:app --reload --port 8000

# 8. Start frontend (new terminal)
cd frontend
npm install
npm run dev
```

### Access the Application

| Service | URL |
|---------|-----|
| **Frontend** | http://localhost:5173 |
| **Backend API** | http://localhost:8000 |
| **API Docs** | http://localhost:8000/docs |
| **Phoenix Observability** | http://localhost:6006 |

---

## ğŸ”­ Observability with Arize Phoenix

Antigravirt includes built-in LLM observability using [Arize Phoenix](https://github.com/Arize-ai/phoenix).

### Features

- **Trace Tree Visualization** â€” See the full execution flow for each query
- **Token Usage Tracking** â€” Monitor input/output tokens per LLM call
- **Latency Analysis** â€” Identify slow nodes in your agent pipeline
- **LLM I/O Inspection** â€” View exact prompts and responses

### Trace Structure

Each query generates a trace tree:

```
Query: "Show me order count by status as a bar chart"
â””â”€â”€ Router (LLM) â†’ DATA_QUERY
    â””â”€â”€ Architect (LLM) â†’ [orders]
        â””â”€â”€ Coder (LLM) â†’ SQL Query
            â””â”€â”€ Executor (MCP) â†’ Query Result
                â””â”€â”€ Viz Router â†’ Needs Visualization
                    â””â”€â”€ Visualizer (LLM) â†’ Plotly Chart
                        â””â”€â”€ Final Responder (LLM) â†’ Answer
```

---

## ğŸ”— API Reference

### REST Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/health` | Health check |
| `GET` | `/api/schema` | Get database schema from all connections |
| `POST` | `/api/query` | Execute a natural language query |
| `GET` | `/api/connections` | List all MCP connections |
| `POST` | `/api/connections` | Add a new data connection |
| `DELETE` | `/api/connections/{id}` | Remove a connection |

### WebSocket

```
ws://localhost:8000/ws/chat
```

**Message Format:**
```json
// Send
{"question": "How many customers are there?"}

// Receive (agent_update)
{"type": "agent_update", "payload": {"agent": "router", "status": "completed"}}

// Receive (final_response)
{"type": "final_response", "payload": {"answer": "...", "visualization": {...}}}
```

---

## ğŸ§ª Example Queries

```
# Simple data queries
"How many customers are there?"
"What is the total revenue from all orders?"
"Show me the top 5 products by price"

# Visualization queries
"Show me order count by status as a bar chart"
"Show me sales distribution as a pie chart"

# Schema exploration
"What tables are in the database?"
"Describe the customers table"
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines before submitting a pull request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

---

<p align="center">
  Built with â¤ï¸ by <a href="https://github.com/kaushikkumarkr">Kaushik Kumar</a>
</p>
